import os
import whisper
import streamlit as st

# Set page config
st.set_page_config(
    page_title="AI Speech to Text converter",
    page_icon="üéôÔ∏è",
    layout="centered",
    initial_sidebar_state="auto",
)

# UI
st.title("–†–∞—Å—à–∏—Ñ—Ä—É–π—Ç–µ –∞—É–¥–∏–æ –∏–ª–∏¬†–≤–∏–¥–µ–æ –≤¬†—Ç–µ–∫—Å—Ç ‚ú®")
st.info(
    "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∞—à —Ñ–∞–π–ª –∏ –ø–æ–ª—É—á–∏—Ç–µ –µ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤—É—é —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É. –°–µ—Ä–≤–∏—Å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—Å–µ¬†–ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –∞—É–¥–∏–æ –∏¬†–≤–∏–¥–µ–æ —Ñ–æ—Ä–º–∞—Ç—ã."
)
st.divider()

upload_files_directory = "uploads/"


# Upload audio or video file
def upload_audio_file():
    # Upload file
    uploaded_object = st.file_uploader(
        type=[
            "opus",
            "mp3",
            "aac",
            "flac",
            "wv",
            "wav",
            "mp4",
            "mov",
            "wmv",
            "webm",
            "avi",
            "mkv",
        ],
        label="–í—ã–±–µ—Ä–∏—Ç–µ –∞—É–¥–∏–æ –∏–ª–∏ –≤–∏–¥–µ–æ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è",
        accept_multiple_files=False,
    )

    # Save uploaded bytes as file
    if uploaded_object is not None:
        with open(
            os.path.join(upload_files_directory, uploaded_object.name), "wb"
        ) as file:
            file.write(uploaded_object.getbuffer())
        return uploaded_object.name
    else:
        return None


# Transcribe audio
def trasncribe(audio):
    model = whisper.load_model("base")
    result = model.transcribe(audio)
    st.write(result["text"])


# Getting name of uploading file to put it into model
audio_file = upload_audio_file()

# Call trasncribe function
action = st.button("–†–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∞—É–¥–∏–æ", type="primary")
if action:
    st.subheader(audio_file)
    st.write(trasncribe(os.path.join(upload_files_directory, audio_file)))
